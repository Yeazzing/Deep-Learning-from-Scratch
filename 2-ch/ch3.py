# -*- coding: utf-8 -*-
"""ch3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xpTJMd9C6DhQrMX3FK9eEyM69HlhpqJ8
"""

import numpy as np
from common.layers import MatMul

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import sys, os
# %cd /content/drive/MyDrive/Colab Notebooks/밑바닥딥러닝2

"""추론 기반 기법과 신경망"""

##완전연결계층에 의한 단어 벡터 변환
c = np.array([[1,0,0,0,0,0,0]])  #입력
W = np.random.randn(7,3)  #가중치
h = np.matmul(c, W)  #중간 노드
print(h)

##방법2 - Matmul 계층으로 수행
c = np.array([[1,0,0,0,0,0,0]])
layer = MatMul(W)
h = layer.forward(c)  #순전파 수행
print(h)

"""단순한 word2vec"""

##CBOW모델의 추론 처리

#샘플 맥락 데이터
c0 = np.array([[1,0,0,0,0,0,0]])
c1 = np.array([[0,0,1,0,0,0,0]])

#가중치 초기화
W_in = np.random.randn(7,3)
W_out = np.random.randn(3,7)

#계층 생성
in_layer0 = MatMul(W_in)  #입력층 처리 (맥락 수만큼 생성)
in_layer1 = MatMul(W_in)  #가중치 W_in 공유
out_layer = MatMul(W_out)

#순전파
h0= in_layer0.forward(c0)
h1= in_layer1.forward(c1)
h = 0.5*(h0+h1)
s = out_layer.forward(h)

print(s)

"""학습 데이터 준비"""

from common.util import preprocess

text = 'You say goodbye and I say hello.'
corpus, word_to_id, id_to_word = preprocess(text)  #말뭉치 텍스트를 단어 ID로 변환

##corpus로부터 맥락과 타깃을 만드는 함수
def create_contexts_target(corpus, window_size=1):
    target = corpus[window_size:-window_size]  #양끝제외
    contexts=[]

    for idx in range(window_size, len(corpus)-window_size):  #타겟의 인덱스범위
        cs = []
        for t in range(-window_size, window_size +1):  #-1, 0, 1
            if t ==0: #타겟일 경우 제외
                continue
            cs.append(corpus[idx+t])  #타겟의 맥락인덱스
        contexts.append(cs)

    return np.array(contexts), np.array(target)

##함수 사용
contexts, target = create_contexts_target(corpus, window_size=1)
print(contexts)
print(target)

##원핫 표현으로 변환
from common.util import preprocess, create_contexts_target, convert_one_hot

text = 'You say goodbye and I say hello.'
corpus, word_to_id, id_to_word = preprocess(text)  #말뭉치를 단어 ID로 변환

contexts, target = create_contexts_target(corpus, window_size=1)  #맥락과 타깃 얻기

vocab_size = len(word_to_id)

#맥락과 타깃 원핫 표현으로 변환
target = convert_one_hot(target, vocab_size) #단어ID목록과 어휘수 인수로 받음
contexts = convert_one_hot(contexts, vocab_size)

print(contexts)
print('-'*10)
print(contexts[:,0])
print(contexts[:,0].shape)

"""CBOW 모델 구현

"""

from common.layers import MatMul, SoftmaxWithLoss

class SimpleCBOW:
    def __init__(self, vocab_size, hidden_size):
        V, H = vocab_size, hidden_size

        #가중치 초기화
        W_in = 0.01*np.random.randn(V, H).astype('f')  #32비트 부동소수점 수로 초기화
        W_out = 0.01*np.random.randn(H, V).astype('f')

        #계층 생성
        self.in_layer0 = MatMul(W_in)  #맥락에서 사용하는 단어의 수만큼 입력MatMul계층 만들기(2개)
        self.in_layer1 = MatMul(W_in)
        self.out_layer = MatMul(W_out)
        self.loss_layer = SoftmaxWithLoss()

        #모든 가중치와 기울기를 리스트에 모은다.
        layers = [self.in_layer0, self.in_layer1, self.out_layer]
        self.params, self.grads = [], []
        for layer in layers:
            self.params += layer.params
            self.grads +=layer.grads

        #인스턴스 변수에 단어의 분산 표현을 저장
        self.word_vecs = W_in

    #순전파 메서드 구현
    def forward(self, contexts, target):
        h0 = self.in_layer0.forward(contexts[:, 0])  #맥락의 첫번째 단어 (6,7)
        h1 = self.in_layer0.forward(contexts[:, 1])  #맥락의 두번째 단어 (6,7)
        h = (h0+h1) *0.5
        score = self.out_layer.forward(h)
        loss = self.loss_layer.forward(score, target)
        return loss

    #역전파 메서드 구현
    def backward(self, dout=1):
        ds = self.loss_layer.backward(dout)
        da = self.out_layer.backward(ds)
        da *= 0.5
        self.in_layer1.backward(da)
        self.in_layer0.backward(da)
        return None

##학습 코드 구현
from common.trainer import Trainer
from common.optimizer import Adam
from simple_cbow import SimpleCBOW
from common.util import preprocess, create_contexts_target, convert_one_hot

window_size = 1
hidden_size = 5
batch_size = 3
max_epoch = 1000

text = 'You say goodbye and I say hello.'
corpus, word_to_id, id_to_word = preprocess(text)  #말뭉치를 단어 ID로 변환

contexts, target = create_contexts_target(corpus, window_size=1)  #맥락과 타깃 얻기
vocab_size = len(word_to_id)

#맥락과 타깃 원핫 표현으로 변환
target = convert_one_hot(target, vocab_size) #단어ID목록과 어휘수 인수로 받음
contexts = convert_one_hot(contexts, vocab_size)

model = SimpleCBOW(vocab_size, hidden_size)
optimizer = Adam()  #매개변서 갱신 방법
trainer = Trainer(model, optimizer)

trainer.fit(contexts, target, max_epoch, batch_size)
trainer.plot()

##학습이 끝난 후의 가중치 매개변수 확인
word_vecs = model.word_vecs
for word_id, word in id_to_word.items():
    print(word, word_vecs[word_id])